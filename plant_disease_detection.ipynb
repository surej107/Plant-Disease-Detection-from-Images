{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69858 images belonging to 38 classes.\n",
      "Found 17474 images belonging to 38 classes.\n",
      "Epoch 1/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6920s\u001b[0m 6s/step - accuracy: 0.1592 - loss: 3.1958 - val_accuracy: 0.3898 - val_loss: 2.1506 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6244s\u001b[0m 6s/step - accuracy: 0.4339 - loss: 1.9125 - val_accuracy: 0.3909 - val_loss: 2.3225 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6690s\u001b[0m 6s/step - accuracy: 0.5380 - loss: 1.5267 - val_accuracy: 0.4753 - val_loss: 2.0795 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7514s\u001b[0m 7s/step - accuracy: 0.6144 - loss: 1.2873 - val_accuracy: 0.4592 - val_loss: 2.5748 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6961s\u001b[0m 6s/step - accuracy: 0.6620 - loss: 1.1322 - val_accuracy: 0.4468 - val_loss: 2.6623 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7893s\u001b[0m 7s/step - accuracy: 0.6923 - loss: 1.0361 - val_accuracy: 0.6281 - val_loss: 1.5865 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9158s\u001b[0m 8s/step - accuracy: 0.7190 - loss: 0.9500 - val_accuracy: 0.5433 - val_loss: 2.0603 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8444s\u001b[0m 8s/step - accuracy: 0.7341 - loss: 0.8998 - val_accuracy: 0.6782 - val_loss: 1.2816 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7629s\u001b[0m 7s/step - accuracy: 0.7474 - loss: 0.8463 - val_accuracy: 0.6885 - val_loss: 1.1674 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7226s\u001b[0m 7s/step - accuracy: 0.7629 - loss: 0.8099 - val_accuracy: 0.7092 - val_loss: 1.1285 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9460s\u001b[0m 9s/step - accuracy: 0.7726 - loss: 0.7748 - val_accuracy: 0.7310 - val_loss: 1.0171 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9654s\u001b[0m 9s/step - accuracy: 0.7818 - loss: 0.7433 - val_accuracy: 0.6017 - val_loss: 1.9607 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7337s\u001b[0m 7s/step - accuracy: 0.7897 - loss: 0.7132 - val_accuracy: 0.7674 - val_loss: 0.8075 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7953s\u001b[0m 7s/step - accuracy: 0.7939 - loss: 0.7006 - val_accuracy: 0.7560 - val_loss: 0.9085 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4440s\u001b[0m 4s/step - accuracy: 0.8001 - loss: 0.6760 - val_accuracy: 0.6772 - val_loss: 1.3974 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4102s\u001b[0m 4s/step - accuracy: 0.8076 - loss: 0.6526 - val_accuracy: 0.7845 - val_loss: 0.7689 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4031s\u001b[0m 4s/step - accuracy: 0.8105 - loss: 0.6415 - val_accuracy: 0.7160 - val_loss: 1.1131 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3960s\u001b[0m 4s/step - accuracy: 0.8178 - loss: 0.6268 - val_accuracy: 0.8179 - val_loss: 0.6108 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4028s\u001b[0m 4s/step - accuracy: 0.8226 - loss: 0.6082 - val_accuracy: 0.7781 - val_loss: 0.8413 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3877s\u001b[0m 4s/step - accuracy: 0.8233 - loss: 0.6071 - val_accuracy: 0.7653 - val_loss: 0.9302 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8281 - loss: 0.5981\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3985s\u001b[0m 4s/step - accuracy: 0.8281 - loss: 0.5981 - val_accuracy: 0.8023 - val_loss: 0.7198 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3926s\u001b[0m 4s/step - accuracy: 0.8458 - loss: 0.5301 - val_accuracy: 0.8344 - val_loss: 0.5925 - learning_rate: 3.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3887s\u001b[0m 4s/step - accuracy: 0.8522 - loss: 0.5098 - val_accuracy: 0.7792 - val_loss: 0.8812 - learning_rate: 3.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4039s\u001b[0m 4s/step - accuracy: 0.8600 - loss: 0.4811 - val_accuracy: 0.7539 - val_loss: 1.0349 - learning_rate: 3.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8650 - loss: 0.4694\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3975s\u001b[0m 4s/step - accuracy: 0.8650 - loss: 0.4694 - val_accuracy: 0.7950 - val_loss: 0.7884 - learning_rate: 3.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3917s\u001b[0m 4s/step - accuracy: 0.8671 - loss: 0.4618 - val_accuracy: 0.8490 - val_loss: 0.5412 - learning_rate: 9.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3920s\u001b[0m 4s/step - accuracy: 0.8717 - loss: 0.4423 - val_accuracy: 0.8712 - val_loss: 0.4416 - learning_rate: 9.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4052s\u001b[0m 4s/step - accuracy: 0.8718 - loss: 0.4440 - val_accuracy: 0.8585 - val_loss: 0.5002 - learning_rate: 9.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5609s\u001b[0m 5s/step - accuracy: 0.8711 - loss: 0.4338 - val_accuracy: 0.8456 - val_loss: 0.5541 - learning_rate: 9.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8726 - loss: 0.4312\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5374s\u001b[0m 5s/step - accuracy: 0.8726 - loss: 0.4312 - val_accuracy: 0.8379 - val_loss: 0.6127 - learning_rate: 9.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'plant_disease_model_v2.h5'.\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 115ms/step - accuracy: 0.8722 - loss: 0.4460\n",
      "Validation Loss: 0.4416092038154602\n",
      "Validation Accuracy: 0.8712372779846191\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "image_size = (64, 64)\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=40,\n",
    "    zoom_range=0.4,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\assignment project\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\train\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\assignment project\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\valid\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=1)\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "model.save('plant_disease_model_v2.h5')\n",
    "print(\"Model saved as 'plant_disease_model_v2.h5'.\")\n",
    "\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting disease.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile disease.py\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "model = tf.keras.models.load_model('plant_disease_model_v2.h5')\n",
    "\n",
    "class_names = [\n",
    "    'Apple___Apple_scab',\n",
    "    'Apple___Black_rot',\n",
    "    'Apple___Cedar_apple_rust',\n",
    "    'Apple___healthy',\n",
    "    'Blueberry___healthy',\n",
    "    'Cherry_(including_sour)___Powdery_mildew',\n",
    "    'Cherry_(including_sour)___healthy',\n",
    "    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
    "    'Corn_(maize)___Common_rust',\n",
    "    'Corn_(maize)___Northern_Leaf_Blight',\n",
    "    'Corn_(maize)___healthy',\n",
    "    'Grape___Black_rot',\n",
    "    'Grape___Esca_(Black_Measles)',\n",
    "    'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
    "    'Grape___healthy',\n",
    "    'Orange___Haunglongbing_(Citrus_greening)',\n",
    "    'Peach___Bacterial_spot',\n",
    "    'Peach___healthy',\n",
    "    'Pepper,_bell___Bacterial_spot',\n",
    "    'Pepper,_bell___healthy',\n",
    "    'Potato___Early_blight',\n",
    "    'Potato___Late_blight',\n",
    "    'Potato___healthy',\n",
    "    'Raspberry___healthy',\n",
    "    'Soybean___healthy',\n",
    "    'Squash___Powdery_mildew',\n",
    "    'Strawberry___Leaf_scorch',\n",
    "    'Strawberry___healthy',\n",
    "    'Tomato___Bacterial_spot',\n",
    "    'Tomato___Early_blight',\n",
    "    'Tomato___Late_blight',\n",
    "    'Tomato___Leaf_Mold',\n",
    "    'Tomato___Septoria_leaf_spot',\n",
    "    'Tomato___Spider_mites Two-spotted_spider_mite',\n",
    "    'Tomato___targetspot',\n",
    "    'Tomato___Yellow_Leaf_Curl_Virus',\n",
    "    'Tomato___Tomato_mosaic_virus',\n",
    "    'Tomato___healthy'\n",
    "]\n",
    "\n",
    "st.title(\"Plant Disease Detection\")\n",
    "st.write(\"Upload an image of a plant leaf, and this app will predict the disease.\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Choose an image file\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file)\n",
    "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "    \n",
    "    def preprocess_image(image):\n",
    "        image = image.resize((64, 64))  \n",
    "        image = np.array(image) / 255.0  \n",
    "        image = np.expand_dims(image, axis=0)  \n",
    "        return image\n",
    "    \n",
    "    processed_image = preprocess_image(image)\n",
    "    \n",
    "    prediction = model.predict(processed_image)\n",
    "    predicted_class = class_names[np.argmax(prediction)]  \n",
    "    confidence = np.max(prediction) * 100  \n",
    "    \n",
    "    st.write(f\"**Prediction:** {predicted_class}\")\n",
    "    st.write(f\"**Confidence:** {confidence:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run disease.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69858 images belonging to 38 classes.\n",
      "Found 17474 images belonging to 38 classes.\n",
      "\n",
      "Training model: MobileNetV2\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5977s\u001b[0m 5s/step - accuracy: 0.6002 - loss: 1.4758 - val_accuracy: 0.8601 - val_loss: 0.4503 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5537s\u001b[0m 5s/step - accuracy: 0.8413 - loss: 0.5016 - val_accuracy: 0.8675 - val_loss: 0.4042 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3520s\u001b[0m 3s/step - accuracy: 0.8609 - loss: 0.4325 - val_accuracy: 0.8784 - val_loss: 0.3765 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4055s\u001b[0m 4s/step - accuracy: 0.8604 - loss: 0.4213 - val_accuracy: 0.8845 - val_loss: 0.3477 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3551s\u001b[0m 3s/step - accuracy: 0.8663 - loss: 0.4092 - val_accuracy: 0.8783 - val_loss: 0.3698 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8699 - loss: 0.3992\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2365s\u001b[0m 2s/step - accuracy: 0.8699 - loss: 0.3992 - val_accuracy: 0.8842 - val_loss: 0.3574 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2231s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3837 - val_accuracy: 0.8975 - val_loss: 0.3078 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2169s\u001b[0m 2s/step - accuracy: 0.8795 - loss: 0.3674 - val_accuracy: 0.8968 - val_loss: 0.3129 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8804 - loss: 0.3672\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2100s\u001b[0m 2s/step - accuracy: 0.8804 - loss: 0.3672 - val_accuracy: 0.8955 - val_loss: 0.3179 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2057s\u001b[0m 2s/step - accuracy: 0.8848 - loss: 0.3543 - val_accuracy: 0.8948 - val_loss: 0.3198 - learning_rate: 2.5000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'plant_disease_model_MobileNetV2.h5'.\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 2s/step - accuracy: 0.8999 - loss: 0.3043\n",
      "Validation Loss (MobileNetV2): 0.3078084886074066\n",
      "Validation Accuracy (MobileNetV2): 0.8975048661231995\n",
      "\n",
      "Training model: EfficientNetB0\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8492s\u001b[0m 8s/step - accuracy: 0.0254 - loss: 3.6946 - val_accuracy: 0.0278 - val_loss: 3.6751 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5883s\u001b[0m 5s/step - accuracy: 0.0266 - loss: 3.6841 - val_accuracy: 0.0288 - val_loss: 3.6617 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4822s\u001b[0m 4s/step - accuracy: 0.0277 - loss: 3.6785 - val_accuracy: 0.0284 - val_loss: 3.6550 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4470s\u001b[0m 4s/step - accuracy: 0.0285 - loss: 3.6796 - val_accuracy: 0.0402 - val_loss: 3.6491 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3959s\u001b[0m 4s/step - accuracy: 0.0274 - loss: 3.6783 - val_accuracy: 0.0250 - val_loss: 3.6487 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4288s\u001b[0m 4s/step - accuracy: 0.0279 - loss: 3.6772 - val_accuracy: 0.0469 - val_loss: 3.6407 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3706s\u001b[0m 3s/step - accuracy: 0.0287 - loss: 3.6735 - val_accuracy: 0.0311 - val_loss: 3.6465 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4302s\u001b[0m 4s/step - accuracy: 0.0287 - loss: 3.6760 - val_accuracy: 0.0252 - val_loss: 3.6365 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5465s\u001b[0m 5s/step - accuracy: 0.0296 - loss: 3.6761 - val_accuracy: 0.0451 - val_loss: 3.6389 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.0293 - loss: 3.6757\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3789s\u001b[0m 3s/step - accuracy: 0.0293 - loss: 3.6757 - val_accuracy: 0.0430 - val_loss: 3.6523 - learning_rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'plant_disease_model_EfficientNetB0.h5'.\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 3s/step - accuracy: 0.0243 - loss: 3.6372\n",
      "Validation Loss (EfficientNetB0): 3.6364874839782715\n",
      "Validation Accuracy (EfficientNetB0): 0.025180267170071602\n",
      "\n",
      "Training model: InceptionV3\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3282s\u001b[0m 3s/step - accuracy: 0.4434 - loss: 2.6685 - val_accuracy: 0.7623 - val_loss: 0.8204 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3459s\u001b[0m 3s/step - accuracy: 0.6882 - loss: 1.2017 - val_accuracy: 0.7863 - val_loss: 0.7707 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3517s\u001b[0m 3s/step - accuracy: 0.7017 - loss: 1.1699 - val_accuracy: 0.7900 - val_loss: 0.7585 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3105s\u001b[0m 3s/step - accuracy: 0.7069 - loss: 1.1756 - val_accuracy: 0.8085 - val_loss: 0.6876 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1909s\u001b[0m 2s/step - accuracy: 0.7109 - loss: 1.1966 - val_accuracy: 0.8089 - val_loss: 0.6912 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7185 - loss: 1.1746\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1744s\u001b[0m 2s/step - accuracy: 0.7185 - loss: 1.1746 - val_accuracy: 0.8059 - val_loss: 0.6915 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1806s\u001b[0m 2s/step - accuracy: 0.7326 - loss: 1.0837 - val_accuracy: 0.8279 - val_loss: 0.6059 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1787s\u001b[0m 2s/step - accuracy: 0.7434 - loss: 1.0127 - val_accuracy: 0.8250 - val_loss: 0.5947 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1801s\u001b[0m 2s/step - accuracy: 0.7431 - loss: 0.9916 - val_accuracy: 0.8282 - val_loss: 0.5734 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1817s\u001b[0m 2s/step - accuracy: 0.7450 - loss: 0.9775 - val_accuracy: 0.8320 - val_loss: 0.5609 - learning_rate: 5.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'plant_disease_model_InceptionV3.h5'.\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 1s/step - accuracy: 0.8327 - loss: 0.5649\n",
      "Validation Loss (InceptionV3): 0.5609433054924011\n",
      "Validation Accuracy (InceptionV3): 0.8320361971855164\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0, InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "image_size = (128, 128)  \n",
    "batch_size = 64          \n",
    "epochs = 10              \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,  \n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\assignment project\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\train\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\assignment project\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\valid\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "def build_model(pretrained_model):\n",
    "    base_model = pretrained_model(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "    base_model.trainable = False  \n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dropout(0.4),\n",
    "        Dense(train_generator.num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "models_to_test = {\n",
    "    'MobileNetV2': MobileNetV2,\n",
    "    'EfficientNetB0': EfficientNetB0,\n",
    "    'InceptionV3': InceptionV3\n",
    "}\n",
    "\n",
    "for model_name, pretrained_model in models_to_test.items():\n",
    "    print(f\"\\nTraining model: {model_name}\\n\")\n",
    "    model = build_model(pretrained_model)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "    model.save(f'plant_disease_model_{model_name}.h5')\n",
    "    print(f\"Model saved as 'plant_disease_model_{model_name}.h5'.\")\n",
    "\n",
    "    loss, accuracy = model.evaluate(val_generator)\n",
    "    print(f\"Validation Loss ({model_name}): {loss}\")\n",
    "    print(f\"Validation Accuracy ({model_name}): {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
